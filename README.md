# 用户画像和行为分析脚本使用指南

## 引言

本指南旨在帮助用户使用指定的 Python 脚本对 30G 和 10G 数据集进行用户画像（User Profiling）、行为分析（Behavior Analysis）以及潜在用户识别（Identifying Potential Users）。这些脚本利用 PySpark 进行分布式处理，结合可视化技术和聚类算法（如 KMeans），以揭示用户特征、行为模式和高价值用户群体。

- **数据集说明**：
  - **30G 数据集**：包含更全面的用户数据，适合大规模分析。
  - **10G 数据集**：较小的数据集，可能为子集或不同样本，适合快速处理。

请根据您的数据集大小选择相应的脚本，并确保运行环境正确配置。

## 任务与脚本对应

以下部分详细说明了每个任务所需的脚本及其功能。

### 1. 建立用户画像和行为分析

用户画像和行为分析通过探索性数据分析（EDA）和数据预处理实现，旨在揭示用户的人口统计特征和行为模式。这些分析有助于理解用户群体并优化产品或营销策略。

- **适用脚本**：
  - **30G 数据集**：`main.py`
    - **功能**：处理大规模数据集，分析用户人口统计特征（如性别分布、年龄分布、地域分布）和行为模式（如登录活动高峰期、不同年龄组的使用习惯）。
    - **输出**：生成可视化报告（如热图、直方图、条形图），展示用户特征和行为洞察。
  - **10G 数据集**：`main_10.py`
    - **功能**：与 `main.py` 类似，但优化为处理较小数据集，适合快速分析。
    - **输出**：提供相同的用户画像和行为分析结果，适用于资源受限的环境。



### 2. 识别潜在用户

潜在用户识别通过 RFM（Recency, Frequency, Monetary）模型和聚类算法（如 KMeans）实现，旨在将用户分为高价值用户、潜力用户和风险用户等类别。这些分组有助于制定个性化营销和用户保留策略。

- **适用脚本**：
  - **30G 数据集**：`rfm_30.py`
    - **功能**：基于 RFM 模型对用户进行评分，并使用聚类算法（如 KMeans，k=3）将用户分为不同群体。
    - **输出**：识别高价值用户（最近 6 个月活跃、年消费 12 次、平均花费 8500 元）、潜力用户（中等活跃度和消费额）和风险用户（24 个月未活跃）。
  - **10G 数据集**：`rfm_10.py`
    - **功能**：与 `rfm_30.py` 类似，但针对较小数据集优化，减少计算资源需求。
    - **输出**：提供相同的 RFM 分析和用户分组结果。

- **分析内容**：
  - **RFM 模型**：
    - **最近性（Recency）**：用户最近一次活跃的时间。
    - **频率（Frequency）**：用户在特定时间段内的消费或登录次数。
    - **货币价值（Monetary）**：用户的总消费金额。
  - **聚类结果**：
    - 高价值用户：忠诚客户，需通过忠诚度计划保留。
    - 潜力用户：可通过交叉销售提升价值。
    - 风险用户：需通过个性化优惠重新吸引。
  - **模型评估**：聚类模型（如 KMeans）可能使用轮廓分数（例如 0.6）评估分离效果，建议与业务结果（如留存率）验证。

- **商业意义**：
  识别用户群体可指导以下策略：
  - 高价值用户：提供独家折扣或高级功能。
  - 潜力用户：通过促销活动提升参与度。
  - 风险用户：通过限时优惠重新吸引。

### 脚本运行示例

以下是运行脚本的示例命令。确保数据集路径正确，并在运行前检查脚本注释以了解任何特定参数。

```bash
# 30G 数据集：用户画像和行为分析
python main.py

# 10G 数据集：用户画像和行为分析
python main_10.py

# 30G 数据集：识别潜在用户
python rfm_30.py

# 10G 数据集：识别潜在用户
python rfm_10.py
```

### 运行环境要求

- **编程语言**：Python 3.x
- **必要库**：
  - PySpark：用于分布式数据处理。
  - Pandas、NumPy：用于数据分析。
  - Matplotlib、Seaborn：用于可视化。
  - Scikit-learn：用于聚类算法（如 KMeans）。
- **安装示例**：
  ```bash
  pip install pyspark pandas numpy matplotlib seaborn scikit-learn
  ```
- **其他**：确保有足够的计算资源（特别是 30G 数据集）并配置好 Spark 环境。

## 注意事项

- **仅运行核心脚本**：项目可能包含其他脚本（如测试或实验脚本），但这些脚本无需运行。请专注于 `main.py`、`main_10.py`、`rfm_30.py` 和 `rfm_10.py`。
- **数据集匹配**：使用错误的脚本（如用 `main.py` 处理 10G 数据集）可能导致性能问题或错误。
- **文档参考**：有关脚本的详细说明，请查看脚本内部注释或项目仓库 [[invalid url, do not cite]]([invalid url, do not cite]) 中的文档。

## 结果预期

以下是运行脚本后可能获得的结果示例：

| 任务                     | 脚本           | 数据集 | 预期输出                                   |
|--------------------------|----------------|--------|--------------------------------------------|
| 用户画像和行为分析       | `main.py`      | 30G    | 性别、年龄、地域分布图表；登录行为热图     |
| 用户画像和行为分析       | `main_10.py`   | 10G    | 同上，但处理时间更短                       |
| 潜在用户识别             | `rfm_30.py`    | 30G    | RFM 分数表；高价值/潜力/风险用户分组      |
| 潜在用户识别             | `rfm_10.py`    | 10G    | 同上，但适用于较小数据集                   |

## 结论

通过使用本指南中列出的脚本，您可以高效地完成用户画像、行为分析和潜在用户识别任务。确保根据数据集大小选择正确的脚本，并按照环境要求配置系统。如需进一步帮助，请参考项目仓库或联系项目负责人。